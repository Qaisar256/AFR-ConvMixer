{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 59093,
          "databundleVersionId": 7469972,
          "sourceType": "competition"
        },
        {
          "sourceId": 7392775,
          "sourceType": "datasetVersion",
          "datasetId": 4297782
        },
        {
          "sourceId": 7402356,
          "sourceType": "datasetVersion",
          "datasetId": 4304475
        },
        {
          "sourceId": 7447509,
          "sourceType": "datasetVersion",
          "datasetId": 4334995
        },
        {
          "sourceId": 7450712,
          "sourceType": "datasetVersion",
          "datasetId": 4336944
        },
        {
          "sourceId": 158958765,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Grad Cam - What is important in Spectrograms?",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qaisar256/AFR-ConvMixer/blob/main/Grad_Cam_What_is_important_in_Spectrograms%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'brain-spectrograms:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4297782%2F7392775%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240405%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240405T135852Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dbc07d6e8ce5ce3c37af006fac7de71c3929639e718ac2a37d37f287e0549d6b6a7ff3c3d7bbd24ac871792d17d21a576b69dbc2679ad1ec621899d7d466cb7cb866e6672241f30ab269f0e5c392a030aab897b8ddba4be1ca9e9c08430ad42589073bde0ddfbc1790f7c97c689d6360a4cbb501100006055f03216a2ff2716e98b433ba593478be0b7c4f09e64a4a5eaeb6187cda7c9fa52f0b04cec93667d83b741c6fea286c1276b72833c63cc7da04987762841a1ea629d8ad244eb7a47acd68d5074acbcaab3b0a26733fedbd3ffdf15fccd411f0332736cff4205074be6b81e483201cdb87382377b7619643d6ad7f452fddb67552af9560805a230b3e9,tf-efficientnet-imagenet-weights:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4304475%2F7402356%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240405%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240405T135852Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Deaae4cf4eaa74da993883cc7c0078821adac15f1ba01dcc74ba46ff2965cb76376f7b3448c2d20fe07162e44eb11248d9c57252ba3dca7c0d6f1dbdb67bbcef6f3bbc6e40d8eac5d2737049a0f8fac09f95dd5c5b9cf86ea1d80891a570abf594c9df995c1815edaaefa7771e50e5e610ec97f74260b6f0ca889aafdc9db0ed6b659e43d6d9f77d0f3fb82376befa8efe77d397f9948381012ab3bd7cd66be85814bb5478da902cf82e84d13343778d56785e578815f14e8338df74fea19f9ab19b32db6ffdf8f9cf1b0c87e450bd032e8094cec889a9282c724d0c91a4907ec1a64dfa018eeab8cee1133eeb92df9f6d0308ab9fd03e3f392c797887fe638b3,brain-eeg-spectrograms:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4334995%2F7447509%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240405%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240405T135852Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Ddae7000227770192d86ca2e949afcf5d9bde431f7bedfdb9c61ce57bf18c289bad47b68628b6e88dd2c877ec7d8abfb1f4aff7ae470d0aad77c54a78a8b0ab78a56a93323a72bf7f64262b405942c154f3a07a3de9aadc04f7ee1f9811eab1dae2ab4ed3e8c2ca33bc264794eb6717291de412b881390788119a84036cde85ead5c18c140f5429d002ccb100205003965bc8bd2d14b56f286807bf9347a19928023d3a33183048e4e2ff99c67d282156cf4bd1237145837b202691f47bf7304a49fdaea48f88c20f84205eadab59d0ef342c5650378f9a8c94a149a2bd92fc0ae99012de8af00aaf54ae092c971dd90c895ad64004d6cba3466cc1189c08b1d3,brain-efficientnet-models-v3-v4-v5:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4336944%2F7450712%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240405%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240405T135852Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dd8cf06a57e7a0e1fd73a4073bf0a4d4d15cde000a7c6e62e33fc02d41774630c1b3bb7ff5248b394d88b085c5ac935994399191cf11d21af4c171b6176d6298580cb45707817122753356cf687d66271c0c6ff223ae5b4a44d69d8d093f583841b389922d03de16a9ddebc643d00693f1e4c9319754b7a843026487f25d378276c7e7e7a210e9deb6551ed35d1758772b4f64cfe7c6e5eba84b260eb05043c6117de7af4bb7854df6c3840f134a61bf13530bc6300087790121393c6958b297b74fe0bbaa461145204cc0518d26881699d6a218d589530c886ead240c450b257959c1ef8909a12caf3eb3b2f327871a81acbc3d42df6f70ccb3be7dd585aeb0e'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "VQjch6JwjkB1",
        "outputId": "f28f5934-a0ac-4427-ee2d-cee1a7bbb11d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading brain-spectrograms, 2861294581 bytes compressed\n",
            "[==================================================] 2861294581 bytes downloaded\n",
            "Downloaded and uncompressed: brain-spectrograms\n",
            "Downloading tf-efficientnet-imagenet-weights, 278957218 bytes compressed\n",
            "[==================================================] 278957218 bytes downloaded\n",
            "Downloaded and uncompressed: tf-efficientnet-imagenet-weights\n",
            "Downloading brain-eeg-spectrograms, 16020628604 bytes compressed\n",
            "[====                                              ] 1540997120 bytes downloaded"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad Cam for Kaggle's Brain Comp\n",
        "This notebook displays Grad Cam for the EfficientNetB0 model trained in version 5 of my EfficientNet starter notebook [here][1]. Grad Cam allows us to see where the model is giving its attention to when it makes a prediction. This helps us understand what is important in the spectrogram images. This knowledge helps us improve preprocessing, or improve model architecture, or engineer better features for our ML models like GBT CatBoost. There is a dicussion about this notebook [here][2]\n",
        "\n",
        "[1]: https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43\n",
        "[2]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/472976"
      ],
      "metadata": {
        "id": "GmzV4lY8jkB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize 2xT4 GPU"
      ],
      "metadata": {
        "id": "bSsN7EKvjkCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
        "import tensorflow as tf\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print('TensorFlow version =',tf.__version__)\n",
        "\n",
        "# USE MULTIPLE GPUS\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(gpus)<=1:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "    print(f'Using {len(gpus)} GPU')\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(f'Using {len(gpus)} GPUs')\n",
        "\n",
        "# USE MIXED PRECISION\n",
        "MIX = True\n",
        "if MIX:\n",
        "    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
        "    print('Mixed precision enabled')\n",
        "else:\n",
        "    print('Using full precision')\n",
        "\n",
        "###############\n",
        "\n",
        "VER = 5\n",
        "\n",
        "# IF THIS EQUALS NONE, THEN WE TRAIN NEW MODELS\n",
        "# IF THIS EQUALS DISK PATH, THEN WE LOAD PREVIOUSLY TRAINED MODELS\n",
        "LOAD_MODELS_FROM = '/kaggle/input/brain-efficientnet-models-v3-v4-v5/'\n",
        "\n",
        "USE_KAGGLE_SPECTROGRAMS = True\n",
        "USE_EEG_SPECTROGRAMS = True"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:39:32.978795Z",
          "iopub.execute_input": "2024-02-03T02:39:32.979096Z",
          "iopub.status.idle": "2024-02-03T02:39:49.643481Z",
          "shell.execute_reply.started": "2024-02-03T02:39:32.979056Z",
          "shell.execute_reply": "2024-02-03T02:39:49.642422Z"
        },
        "trusted": true,
        "id": "1JbH44uvjkCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Train Data and Create Non-Overlapping Eeg Ids"
      ],
      "metadata": {
        "id": "FGULgJRDjkCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
        "TARGETS = df.columns[-6:]\n",
        "print('Train shape:', df.shape )\n",
        "print('Targets', list(TARGETS))\n",
        "\n",
        "###########\n",
        "\n",
        "train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
        "    {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
        "train.columns = ['spec_id','min']\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
        "    {'spectrogram_label_offset_seconds':'max'})\n",
        "train['max'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
        "train['patient_id'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[TARGETS].agg('sum')\n",
        "for t in TARGETS:\n",
        "    train[t] = tmp[t].values\n",
        "\n",
        "y_data = train[TARGETS].values\n",
        "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
        "train[TARGETS] = y_data\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
        "train['target'] = tmp\n",
        "\n",
        "train = train.reset_index()\n",
        "print('Train non-overlapp eeg_id shape:', train.shape )\n",
        "train.head()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:39:49.645351Z",
          "iopub.execute_input": "2024-02-03T02:39:49.645931Z",
          "iopub.status.idle": "2024-02-03T02:39:50.020166Z",
          "shell.execute_reply.started": "2024-02-03T02:39:49.6459Z",
          "shell.execute_reply": "2024-02-03T02:39:50.019206Z"
        },
        "trusted": true,
        "id": "HQWLIyuxjkCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Train Spectrograms and EEG Spectrograms"
      ],
      "metadata": {
        "id": "TMOshoFzjkCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "READ_SPEC_FILES = False\n",
        "\n",
        "# READ ALL SPECTROGRAMS\n",
        "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\n",
        "files = os.listdir(PATH)\n",
        "print(f'There are {len(files)} spectrogram parquets')\n",
        "\n",
        "if READ_SPEC_FILES:\n",
        "    spectrograms = {}\n",
        "    for i,f in enumerate(files):\n",
        "        if i%100==0: print(i,', ',end='')\n",
        "        tmp = pd.read_parquet(f'{PATH}{f}')\n",
        "        name = int(f.split('.')[0])\n",
        "        spectrograms[name] = tmp.iloc[:,1:].values\n",
        "else:\n",
        "    spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()\n",
        "\n",
        "###########\n",
        "\n",
        "READ_EEG_SPEC_FILES = False\n",
        "\n",
        "if READ_EEG_SPEC_FILES:\n",
        "    all_eegs = {}\n",
        "    for i,e in enumerate(train.eeg_id.values):\n",
        "        if i%100==0: print(i,', ',end='')\n",
        "        x = np.load(f'/kaggle/input/brain-eeg-spectrograms/EEG_Spectrograms/{e}.npy')\n",
        "        all_eegs[e] = x\n",
        "else:\n",
        "    all_eegs = np.load('/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()\n",
        "\n",
        "print(f'There are {len(all_eegs)} eeg parquets')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:39:50.021444Z",
          "iopub.execute_input": "2024-02-03T02:39:50.021768Z",
          "iopub.status.idle": "2024-02-03T02:41:55.37038Z",
          "shell.execute_reply.started": "2024-02-03T02:39:50.021734Z",
          "shell.execute_reply": "2024-02-03T02:41:55.369257Z"
        },
        "trusted": true,
        "id": "8vITZNzfjkCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "v3jAO4WCjkCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as albu\n",
        "TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
        "TARS2 = {x:y for y,x in TARS.items()}\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, data, batch_size=32, shuffle=False, augment=False, mode='train',\n",
        "                 specs = spectrograms, eeg_specs = all_eegs):\n",
        "\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.mode = mode\n",
        "        self.specs = specs\n",
        "        self.eeg_specs = eeg_specs\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        ct = int( np.ceil( len(self.data) / self.batch_size ) )\n",
        "        return ct\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X, y = self.__data_generation(indexes)\n",
        "        if self.augment: X = self.__augment_batch(X)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange( len(self.data) )\n",
        "        if self.shuffle: np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "        X = np.zeros((len(indexes),128,256,8),dtype='float32')\n",
        "        y = np.zeros((len(indexes),6),dtype='float32')\n",
        "        img = np.ones((128,256),dtype='float32')\n",
        "\n",
        "        for j,i in enumerate(indexes):\n",
        "            row = self.data.iloc[i]\n",
        "            if self.mode=='test':\n",
        "                r = 0\n",
        "            else:\n",
        "                r = int( (row['min'] + row['max'])//4 )\n",
        "\n",
        "            for k in range(4):\n",
        "                # EXTRACT 300 ROWS OF SPECTROGRAM\n",
        "                img = self.specs[row.spec_id][r:r+300,k*100:(k+1)*100].T\n",
        "\n",
        "                # LOG TRANSFORM SPECTROGRAM\n",
        "                img = np.clip(img,np.exp(-4),np.exp(8))\n",
        "                img = np.log(img)\n",
        "\n",
        "                # STANDARDIZE PER IMAGE\n",
        "                ep = 1e-6\n",
        "                m = np.nanmean(img.flatten())\n",
        "                s = np.nanstd(img.flatten())\n",
        "                img = (img-m)/(s+ep)\n",
        "                img = np.nan_to_num(img, nan=0.0)\n",
        "\n",
        "                # CROP TO 256 TIME STEPS\n",
        "                X[j,14:-14,:,k] = img[:,22:-22] / 2.0\n",
        "\n",
        "            # EEG SPECTROGRAMS\n",
        "            img = self.eeg_specs[row.eeg_id]\n",
        "            X[j,:,:,4:] = img\n",
        "\n",
        "            if self.mode!='test':\n",
        "                y[j,] = row[TARGETS]\n",
        "\n",
        "        return X,y\n",
        "\n",
        "    def __random_transform(self, img):\n",
        "        composition = albu.Compose([\n",
        "            albu.HorizontalFlip(p=0.5),\n",
        "            #albu.CoarseDropout(max_holes=8,max_height=32,max_width=32,fill_value=0,p=0.5),\n",
        "        ])\n",
        "        return composition(image=img)['image']\n",
        "\n",
        "    def __augment_batch(self, img_batch):\n",
        "        for i in range(img_batch.shape[0]):\n",
        "            img_batch[i, ] = self.__random_transform(img_batch[i, ])\n",
        "        return img_batch"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:41:55.373138Z",
          "iopub.execute_input": "2024-02-03T02:41:55.373472Z",
          "iopub.status.idle": "2024-02-03T02:41:57.344119Z",
          "shell.execute_reply.started": "2024-02-03T02:41:55.373445Z",
          "shell.execute_reply": "2024-02-03T02:41:57.342928Z"
        },
        "trusted": true,
        "id": "4D_o1iNGjkCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Grad Cam Model"
      ],
      "metadata": {
        "id": "yNqHQmtXjkCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:41:57.345495Z",
          "iopub.execute_input": "2024-02-03T02:41:57.346111Z",
          "iopub.status.idle": "2024-02-03T02:42:12.995466Z",
          "shell.execute_reply.started": "2024-02-03T02:41:57.346058Z",
          "shell.execute_reply": "2024-02-03T02:42:12.994339Z"
        },
        "trusted": true,
        "id": "j6UFoWW6jkCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import efficientnet.tfkeras as efn\n",
        "\n",
        "def build_cam_model(pretrain=None):\n",
        "\n",
        "    inp = tf.keras.Input(shape=(128,256,8))\n",
        "    base_model = efn.EfficientNetB0(include_top=False, weights=None, input_shape=None)\n",
        "    if pretrain:\n",
        "        base_model.load_weights('/kaggle/input/tf-efficientnet-imagenet-weights/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n",
        "\n",
        "    # RESHAPE INPUT 128x256x8 => 512x512x3 MONOTONE IMAGE\n",
        "    # KAGGLE SPECTROGRAMS\n",
        "    x1 = [inp[:,:,:,i:i+1] for i in range(4)]\n",
        "    x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n",
        "    # EEG SPECTROGRAMS\n",
        "    x2 = [inp[:,:,:,i+4:i+5] for i in range(4)]\n",
        "    x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n",
        "    # MAKE 512X512X3\n",
        "    if USE_KAGGLE_SPECTROGRAMS & USE_EEG_SPECTROGRAMS:\n",
        "        x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n",
        "    elif USE_EEG_SPECTROGRAMS: x = x2\n",
        "    else: x = x1\n",
        "    x = tf.keras.layers.Concatenate(axis=3)([x,x,x])\n",
        "\n",
        "    # OUTPUT\n",
        "    x0 = base_model(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x0)\n",
        "    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    # COMPILE MODEL\n",
        "    model = tf.keras.Model(inputs=inp, outputs=[x,x0])\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "    loss = tf.keras.losses.KLDivergence()\n",
        "\n",
        "    model.compile(loss=loss, optimizer = opt)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T02:42:12.997012Z",
          "iopub.execute_input": "2024-02-03T02:42:12.997375Z",
          "iopub.status.idle": "2024-02-03T02:42:13.038746Z",
          "shell.execute_reply.started": "2024-02-03T02:42:12.997344Z",
          "shell.execute_reply": "2024-02-03T02:42:13.037816Z"
        },
        "trusted": true,
        "id": "VAx6vydQjkCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for fold, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):\n",
        "    # LOAD WEIGHTS INTO GRAD CAM MODEL\n",
        "    with strategy.scope():\n",
        "        model = build_cam_model()\n",
        "    model.load_weights(f'{LOAD_MODELS_FROM}EffNet_v{VER}_f{fold}.h5')\n",
        "    layer_weights = model.layers[-1].get_weights()[0][:,0]\n",
        "    break\n",
        "\n",
        "print('Using fold 0 model and inferring fold 0 OOF (out of fold) samples...')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:42:13.040113Z",
          "iopub.execute_input": "2024-02-03T02:42:13.041035Z",
          "iopub.status.idle": "2024-02-03T02:42:19.550338Z",
          "shell.execute_reply.started": "2024-02-03T02:42:13.041009Z",
          "shell.execute_reply": "2024-02-03T02:42:19.549147Z"
        },
        "trusted": true,
        "id": "SfvA_mJdjkCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display Grad Cam\n",
        "With grad cam, given a specific OOF (out of fold) train sample, we can view both a model's prediction and where it looked to make this prediction. In the plots below we display the image that was fed into our image model, in my popular starter notebook, there are 8 spectrograms that have been tiled into one 1 input image.\n",
        "\n",
        "On the left we have the 4 Kaggle spectrograms where each is 10 minutes long. Each represents one of the 4 montages LL, RL, LP, RP. (Montages explained [here][1]) On the right, we have the 4 EEG spectrograms where each is 50 seconds long. The EEG spectrograms are made from the Magic Formula [here][2]. The spectrograms are each `128x256x1`, so the final concatenation is `512x512x1`.\n",
        "\n",
        "![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Feb-2024/key2.png)\n",
        "\n",
        "Each plot below has 3 subplots. The middle and right subplot use the KEY above. The left subplot is just the Grad Cam image where larger values (more yellow) indicates more attention. The middle subplot is the contours of the Grad Cam's 10% largest values superimposed over the image that we fed into our model. The right subplot is also Grad Cam contour superimposed over image but we add an emboss filter to the image to make the details more visible to humans. For explanations about specific grad cam examples, see discussion [here][3]\n",
        "\n",
        "[1]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467877\n",
        "[2]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/469760\n",
        "[3]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/472976"
      ],
      "metadata": {
        "id": "oww3QxUjjkCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# HELPER FUNCTION\n",
        "def mask2contour(mask, width=5):\n",
        "    w = mask.shape[1]\n",
        "    h = mask.shape[0]\n",
        "    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n",
        "    mask2 = np.logical_xor(mask,mask2)\n",
        "    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n",
        "    mask3 = np.logical_xor(mask,mask3)\n",
        "    return np.logical_or(mask2,mask3)\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=16.0, tileGridSize=(8,8))"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:42:19.551463Z",
          "iopub.execute_input": "2024-02-03T02:42:19.551759Z",
          "iopub.status.idle": "2024-02-03T02:42:19.561052Z",
          "shell.execute_reply.started": "2024-02-03T02:42:19.551734Z",
          "shell.execute_reply": "2024-02-03T02:42:19.560018Z"
        },
        "trusted": true,
        "id": "GuB-Z3AEjkCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH = 128\n",
        "\n",
        "for ii,tt in enumerate(TARGETS):\n",
        "    ttt = tt.split('_')[0].upper()\n",
        "\n",
        "    print()\n",
        "    print('#'*25)\n",
        "    print('###',tt.upper())\n",
        "    print('#'*25)\n",
        "\n",
        "    # FIND TRAIN SAMPLES IN OOF (OUT OF FOLD) WITH TARGET >= 0.5\n",
        "    IDX = train.loc[train.index.isin(valid_index) & (train[tt]>=0.5),TARGETS].index.values\n",
        "    print(f'Found {len(IDX)} samples in fold zero OOF for {tt} with true>0.5')\n",
        "\n",
        "    # INFER TRAIN SAMPLES WITH MODEL (SAVE PREDS AND ACTIVATIONS)\n",
        "    valid_gen = DataGenerator(train.iloc[IDX[:128]], shuffle=False, batch_size=BATCH, mode='valid')\n",
        "    p,xx = model.predict(valid_gen,verbose=0)\n",
        "    #print(xx.shape)\n",
        "\n",
        "    # DISPLAY GRAD CAM\n",
        "    for x,y in valid_gen:\n",
        "        ct = 0\n",
        "        for i in range(BATCH):\n",
        "\n",
        "            # FIND SAMPLES WITH PRED >= 0.5 FOR TARGET\n",
        "            if i>=len(p): continue\n",
        "            pred = p[i]\n",
        "            if pred[ii]<0.5: continue\n",
        "\n",
        "            # FORMAT PREDICTIONS AS STRING\n",
        "            pred2 = ''; true2 = ''\n",
        "            true = train.loc[IDX[i]][TARGETS].values\n",
        "            for j,t in enumerate(TARGETS):\n",
        "                n = t.split('_')[0]\n",
        "                pred2 += f' {n}={pred[j]:0.3f}'\n",
        "                true2 += f' {n}={true[j]:0.3f}'\n",
        "            print()\n",
        "            print('==> TRUE:',true2)\n",
        "            print('==> PRED:',pred2)\n",
        "\n",
        "            # PLOT GRAD CAM RESULTS\n",
        "            plt.figure(figsize=(20,8))\n",
        "\n",
        "            # PLOT GRAD CAM IMAGE (PLOT 1 OF 3)\n",
        "            plt.subplot(1,3,1)\n",
        "            img = np.sum(xx[i,] * layer_weights,axis=-1)\n",
        "            img = cv2.resize(img,(512,512))\n",
        "            plt.imshow(img[::-1,])\n",
        "            plt.title(f'{ttt} - Grad Cam',size=14)\n",
        "\n",
        "            # FIND GRAD CAM CONTOURS FOR AREAS OF INTEREST\n",
        "            cut = np.percentile(img.flatten(), [90])[0]\n",
        "            cntr = img.copy()\n",
        "            cntr[cntr>=cut] = 100\n",
        "            cntr[cntr<cut] = 0\n",
        "            cntr = mask2contour(cntr)\n",
        "\n",
        "            # PLOT EMBOSSED SPECTROGRAMS WITH GRADCAM CONTOURS (PLOT 3 OF 3)\n",
        "            plt.subplot(1,3,3)\n",
        "            x1 = [x[i,:,:,k:k+1] for k in range(4)] #KAGGLE-SPECS: LL RL LP RP\n",
        "            x1 = np.concatenate(x1,axis=0)\n",
        "            x2 = [x[i,:,:,k+4:k+5] for k in range(4)] #EEG-SPECS: LL LP RL RP\n",
        "            x2 = np.concatenate(x2,axis=0)\n",
        "            x3 = np.concatenate([x1,x2],axis=1)\n",
        "            img = cv2.resize(x3,(512,512))\n",
        "            img0 = img.copy()\n",
        "\n",
        "            # EMBOSS IMAGE FOR IMAGE FEATURE VISIBILITY\n",
        "            img = img[1:,1:] - img[:-1,:-1] #emboss\n",
        "            img -= np.min(img)\n",
        "            img /= np.max(img)\n",
        "            img = (img*255).astype('uint8')\n",
        "            img = cv2.GaussianBlur(img,(5,5),0)\n",
        "            img = clahe.apply(img)\n",
        "            mx = np.max(img)\n",
        "\n",
        "            cntr2 = cntr[1:,1:]\n",
        "            img[cntr2>0] = mx\n",
        "            plt.imshow(img[::-1,])\n",
        "            plt.title(f'{ttt} - Embossed Spectrogram with Grad Cam Contours',size=14)\n",
        "\n",
        "            # PLOT SPECTROGRAMS WITH GRADCAM CONTOURS (PLOT 2 OF 3)\n",
        "            plt.subplot(1,3,2)\n",
        "            mx = np.max(img0)\n",
        "            img0[cntr>0] = mx\n",
        "            plt.imshow(img0[::-1,])\n",
        "            plt.title(f'{ttt} - Spectrogram with Grad Cam Contours',size=14)\n",
        "\n",
        "            plt.show()\n",
        "            ct += 1\n",
        "            if ct==8: break\n",
        "\n",
        "        break"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-02-03T02:42:19.562522Z",
          "iopub.execute_input": "2024-02-03T02:42:19.562809Z",
          "iopub.status.idle": "2024-02-03T02:43:42.794885Z",
          "shell.execute_reply.started": "2024-02-03T02:42:19.562785Z",
          "shell.execute_reply": "2024-02-03T02:43:42.793849Z"
        },
        "trusted": true,
        "id": "tl-0hV2QjkCI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}